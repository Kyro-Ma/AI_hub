# 早安！今天是2026年1月5日星期一
AI圈日报|每日为您提供新鲜的人工智能领域资讯

<img src="../../ai_podcast_logo.jpg" alt="AI圈日报" width="320">

## 今日AI资讯一览
- 1. 微星发布 Cubi NUC AI+ 3MG 迷你主机：双 2.5G 网口，最高酷睿 Ultra 9 386H 处理器
- 2. 英伟达升级 RTX AI PC 性能：模型提速 40%、创意生成提升 4.6 倍
- 3. 英伟达发布 DGX Station 桌面 AI 超算，单机运行 1 万亿参数模型
- 4. 摩托罗拉首款“AI 感知伴侣”硬件曝光：像饰品、无屏幕，做你的“第二双眼”
- 5. 剑指 Waymo：英伟达 L4 级自动驾驶出租车最早 2027 年上路
- 6. 英伟达黄仁勋：开源模型彻底改变 AI，较最前沿模型差距缩至 6 个月
- 7. 英伟达黄仁勋推出 Alpamayo 1 开源模型：增强复杂自动驾驶场景下 AI 决策能力
- 8. 10 万亿 tokens！英伟达贡献全球最大规模开源数据集，并推四大开源 AI 模型
- 9. 手提箱里的超级计算机：美国公司将 AI 数据中心缩小至随身行李大小

## 1. 微星发布 Cubi NUC AI+ 3MG 迷你主机：双 2.5G 网口，最高酷睿 Ultra 9 386H 处理器
微星在CES 2026展会上推出Cubi NUC AI+ 3MG迷你主机，体积仅0.51升，便携性强。该设备搭载英特尔Panther Lake架构处理器，集成第五代神经网络处理单元NPU5，AI运算性能达50 TOPS，并通过Windows 11 AI+ PC认证。提供三种配置选项，包括酷睿Ultra 5 322、Ultra 7 355及旗舰级Ultra 9 386H，后者拥有16个计算核心和4个核心Xe3 GPU，支持轻量级创作与多媒体应用。内部配备两个SO-DIMM插槽，支持最高32GB内存，另设一个NVMe插槽用于高速固态硬盘扩展。支持双雷电4接口，可同时连接四台显示器，配备WiFi 7和双2.5G以太网口，提升网络性能。电源键集成指纹识别，增强安全性和便捷性。

## 2. 英伟达升级 RTX AI PC 性能：模型提速 40%、创意生成提升 4.6 倍
英伟达宣布对RTX AI PC进行免费性能升级，引入原生NVFP4和NVFP8数据格式，显著提升AI处理效率。在大语言模型方面，GPT-OSS、Nemotron Nano V2等模型运行速度最高提升40%；创意生成工具如ComfyUI Flux.1性能提升达4.6倍，模型体积缩小最高60%，并支持将部分计算负载卸载至系统内存，缓解显存瓶颈。NVFP4将原本需16个存储单元的浮点数压缩至4个单元，有效降低硬件要求，使中端PC也能流畅运行复杂AI模型。基于RTX的LTX-2音频转视频模型可在20秒内生成4K视频，配合NVFP8实现2.0倍性能提升。RTX视频超分辨率技术将于2月上线ComfyUI，实现720p视频至4K的全流程生成与超分，10秒视频处理时间由15分钟缩短至3分钟。此外，Nexa Hyperlink新增AI视频搜索功能，支持基于RTX优化的本地视频、图像和文档快速检索。

## 3. 英伟达发布 DGX Station 桌面 AI 超算，单机运行 1 万亿参数模型
英伟达在CES 2026期间发布DGX Spark与DGX Station两款桌面级AI超算，基于最新Grace Blackwell架构，配备大容量统一内存和千万亿次AI算力。DGX Spark面向1000亿参数模型，采用NVFP4格式压缩模型至70%大小且不损失性能，运行FLUX.2视频生成模型速度达MacBook Pro M4 Max的8倍，与llama.cpp等开源工具协同提升35%性能。DGX Station搭载GB300 Grace Blackwell Ultra芯片，配备775GB FP4精度一致性内存，可本地运行高达1万亿参数模型，支持Kimi-K2 Thinking、DeepSeek-V3.2、Mistral Large 3、Llama 4 Maverick及gpt-oss-120b等前沿模型，FP4格式将显存占用降至FP16的四分之一，吞吐量提升2至3倍。两款设备均支持NVIDIA AI Enterprise软件栈，提供机器人、基因组学与金融分析等场景开发指南，DGX Spark由戴尔、惠普、联想、华硕等厂商发售，DGX Station将于年内正式上市。

## 4. 摩托罗拉首款“AI 感知伴侣”硬件曝光：像饰品、无屏幕，做你的“第二双眼”
摩托罗拉发布代号为“Project Maxwell”的概念硬件，被定义为“AI 感知伴侣”。该设备采用紧凑矩形设计，材质为塑料、硅胶或织物，外观类似配饰，可别于衣物、包带或项链，强调便携性与时尚性。设备无传统显示屏，取而代之的是一个突出的摄像头模组和多个实体按键，设计灵感源自Humane AI Pin等产品。其核心功能是实现环境感知，通过摄像头捕捉用户所见场景，结合多模态AI技术理解周围环境，实现主动式交互，而非依赖语音指令的被动响应。该设备标志着摩托罗拉在环境计算领域的探索，意图拓展智能手机之外的硬件应用场景，推动人机交互方式的革新。

## 5. 剑指 Waymo：英伟达 L4 级自动驾驶出租车最早 2027 年上路
英伟达在CES 2026主题演讲中宣布，其首款全栈自动驾驶汽车将于2026年第一季度在美国开展测试，计划于2027年与合作伙伴共同推出L4级自动驾驶出租车服务，实现特定区域内的无人干预驾驶。该服务将基于端到端视觉语言模型与规则安全栈双系统架构，确保复杂场景下的行车安全。测试初期采用“有限开放”模式，由未公开的合作伙伴协同运营，标志着英伟达从芯片供应商向自动驾驶车队运营的延伸。公司推出的Drive AGX Thor车载平台售价约3500美元，旨在降低车企研发成本并加速产品上市。在旧金山实测中，搭载该技术的梅赛德斯-奔驰CLA车型在90%路程中实现自动驾驶，但双向堵车等场景仍需人工介入。英伟达目标于2026年底实现城市导航能力，2028年推出消费级点对点自动驾驶，并最终通过生成式AI实现汽车与人类相似的交互与驾驶体验。

## 6. 英伟达黄仁勋：开源模型彻底改变 AI，较最前沿模型差距缩至 6 个月
在CES 2026主题演讲中，英伟达CEO黄仁勋指出人工智能正以惊人速度普及并深刻改变世界。他强调开源AI模型虽目前相比最前沿模型存在约六个月的技术差距，但这一差距正在逐步缩小。黄仁勋认为开源不仅推动了模型发展，更通过开放训练数据使更多开发者能够参与其中，从而加速人工智能的普及与创新。他明确表示，公司不仅开源了AI模型，还同步开放了用于训练模型的数据集，以增强透明度和可验证性。这一举措被视作推动AI生态发展的重要一步，有助于构建更开放、协作的行业环境。

## 7. 英伟达黄仁勋推出 Alpamayo 1 开源模型：增强复杂自动驾驶场景下 AI 决策能力
在CES 2026主题演讲中，英伟达首席执行官黄仁勋推出Alpamayo 1，这是首个面向自动驾驶车辆的开放式大规模视觉-语言-动作模型（VLA），融合因果链推理与轨迹规划技术，旨在提升复杂驾驶场景下的AI决策能力。该模型具备环境理解与行为解释功能，通过开环指标、闭环仿真及真实车辆测试验证，在推理准确性、轨迹生成、行为对齐、安全性与响应延迟等方面达到行业领先水平。Alpamayo 1将可解释的决策过程与精确的车辆控制相结合，为实现L4级自动驾驶提供了可落地的技术路径，标志着自动驾驶在复杂场景下决策能力的重大突破。

## 8. 10 万亿 tokens！英伟达贡献全球最大规模开源数据集，并推四大开源 AI 模型
在CES 2026主题演讲中，英伟达宣布发布涵盖语言、机器人、自动驾驶和医疗四大领域的开源模型与数据集，其中包含10万亿语言训练tokens、50万条机器人轨迹、45.5万个蛋白质结构及100TB车辆传感器数据，构建覆盖多场景的开放AI生态系统。Nemotron系列模型在语音识别和内容安全方面性能提升显著，已被博世、CrowdStrike等企业采用。Cosmos平台结合Isaac系统，赋予机器人物理世界推理与环境生成能力，支持虚拟环境行为验证。Alpamayo系列推出首个面向自动驾驶的视觉语言动作模型，配套开源仿真框架与1700小时真实驾驶数据，助力高阶自动驾驶研发。Clara模型包括La-Proteina、ReaSyn v2和KERMT等，支持蛋白质设计、可合成性评估及药物-人体相互作用预测，结合新数据集推动药物研发效率提升。多家科技企业已基于该生态构建下一代AI系统。

## 9. 手提箱里的超级计算机：美国公司将 AI 数据中心缩小至随身行李大小
美国加州初创企业ODINN在2026年国际消费电子展前夕推出一款尺寸相当于登机箱的人工智能超级计算机OMNIA，具备与大型数据中心相当的算力，集成了CPU、GPU和存储设备，部署时间缩短至数分钟，无需建设机房即可在办公室、医院或保密场所直接使用。该设备配备自主研发的闭环冷却系统，支持高负载运行且低噪音。为满足扩展需求，ODINN推出模块化“无限立方”集群系统，由多个OMNIA单元组成，实现算力弹性扩容，各单元独立运行并自带散热。系统通过自研软件“神经边缘”与主流AI框架深度兼容，实现算力智能调度，提升任务执行效率。该方案旨在为金融、医疗、国防等对数据安全和隐私要求高的行业提供本地化、高性能、低延迟的人工智能算力支持，解决传统云端数据传输风险与本地部署成本高的双重难题。
